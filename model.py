"""
Created on Mon Jun 26 16:48:09 2017

@author: sclegg

Udacity CarND Term1 Project 3--Behavior Training

Objective is to train a car to successfully steer around
one lap of a simulated course.

Training data is acquired from three cameras (mounted center, left and right)
in addition to the steering angle. The car is manually driven around the track
collecting this data.  The camera image data is input into a neural network
and the output of the network is the steering angle.

The neural network design used for this project is the design published
by NVIDA--https://devblogs.nvidia.com/parallelforall/deep-learning-self-driving-cars
"""
import csv
import cv2
import numpy as np
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.optimizers import Adam
from keras.layers.core import Dense, Flatten, Lambda, Dropout
from keras.layers.convolutional import Convolution2D, Cropping2D
from keras.callbacks import EarlyStopping

# Load driving log from test drive directory.
#   Open csv file of driving log and read each line
#   storing the each line in a list defined as lines.
def load_data(directory):    
    lines = []
    with open(directory + '/driving_log.csv') as csvfile:
        reader = csv.reader(csvfile)
        for line in reader:
            for i in range(3):
                line[i] = get_image_file_path(line[i], directory)
            lines.append(line)
    csvfile.close()
    return lines

# Redefine the image filename path to be the
# the current directory path plus IMG plus the image filename.
# Use the split function with [-1] to obtain the image filename
# concatenated with current path and IMG.
def get_image_file_path(source_path, directory):
    filename = source_path.split('/')[-1]
    current_path = directory + '/IMG/' + filename
    return current_path

# Read the camera image for the batch of csv driving log
# lines passed in.  It is assumed that three camera images
# are input per line.  The camera steering angle are adjusted
# baed on the angles the three cameras are mounted.  The steering
# correction angles are given by the correction_angles array.
def add_camera_data(lines, correction_angles):
    images, measurements = [], []
    for line in lines:
        center_steering = float(line[3])
        for i in range(3):  #do center, left and right
            images.append(cv2.imread((line[i])))
            measurements.append(center_steering + correction_angles[i])        
    return (images, measurements)

# Normalize the image to a range of -.5 to .5 (it is assumed that the
# image is uint8 hence the max value is 255 and the min value is 0).
def normalize (x):
    return (x/255.0 - 0.5)

# Create pseudo data to increase the training data set.  The pseduo data
# is generated by mirroring each image around the vertical axis (y).
# The steering angle for each flipped image is the negitive of the 
# steering angle of the original image.
def augment_data(images, measurements):
    augmented_images, augmented_measurements = [], []
    for image, measurement in zip(images, measurements):
        augmented_images.append(image)
        augmented_measurements.append(measurement)
        augmented_images.append(cv2.flip(image,1))  #flip vertical
        augmented_measurements.append(measurement*-1.0) #flip steering angle
    return (augmented_images, augmented_measurements)

# Batch generator.  Load batch_size csv lines then obtain and augment image data
# for the batch and yield the images and measurements back.
def generator(lines, batch_size, image_shape, nb_classes,
              n_augment, correction_angles, Shuffle=True):
    # shuffle training data
    # Create empty arrays to contain batch of features and labels
    # Yield batch_features and batch_labels
    batch_features = np.zeros(( (batch_size*n_augment,) + image_shape ))
    batch_labels = np.zeros(( batch_size*n_augment, nb_classes ))
    while True:
        for offset in range(0, len(lines), batch_size):
            end = offset + batch_size
            line_batch = lines[offset:end]
            images, measurements = add_camera_data(line_batch, correction_angles)
            images, measurements = augment_data(images, measurements)
            batch_features = np.array(images)
            batch_labels = np.array(measurements)
            if Shuffle == True:
                batch_features, batch_labels = shuffle(batch_features, batch_labels)
            yield (batch_features, batch_labels)

#######
# Define test drive training directories to use for training the neural network
directories = ['testdrive1', 'testdrive4', 'testdrive6']

# Load in all the driving logs from the training directories and store the
# in the lines list
lines = []
for directory in directories:
    print("loading {}".format(directory))
    lines.extend(load_data(directory))
print("loaded {} lines from cvs data files".format(len(lines)))

# Split the driving log into an training set and a validation set.
train_cvs, valid_cvs = train_test_split(lines, test_size=0.2)

# Get the image shape from the first image listed in the driving log
image_shape = np.array(cv2.imread(lines[0][0])).shape

# Define the number of measurement classes (nb_classes)
nb_classes = 1

# Define the camera corrections angles
#   Center camera = 0.0
#   Left camera   = 0.1
#   Right camera  =-0.1
# The correction angles were determined by measurment from the images.
correction_angles = [0.0, +0.1, -0.1]

# Generator batch size 
batch_size = 48

n_augment = 6 #three cameras (correction angles) times mirror of all images

# Number of generator steps for training and validation
train_steps = int(len(train_cvs)*n_augment)
valid_steps = int(len(valid_cvs)*n_augment)

print("Step per epoch is {}".format(train_steps))
print("Image shape is {}".format(image_shape))

# Define the training (fit) and validation generators
fit_generator = generator(train_cvs, batch_size, image_shape, nb_classes,
                          n_augment, correction_angles)
val_generator = generator(valid_cvs, batch_size, image_shape, nb_classes,
                          n_augment, correction_angles, Shuffle=False)

# Define the NVIDA neural netowrk per blog post cited above.
model = Sequential()

# Crop the top and bottom of the images.  The top 60 pixels and bottom 20
# pixels were removed.
model.add(Cropping2D(cropping=((60,20),(0,0)), input_shape=image_shape))

# Normalize the image data
model.add(Lambda(normalize))

# NVIDA network
model.add(Convolution2D(24, 5, 5, subsample=(2,2), activation='relu'))
model.add(Convolution2D(36, 5, 5, subsample=(2,2), activation='relu'))
model.add(Convolution2D(48, 5, 5, subsample=(2,2), activation='relu'))
model.add(Convolution2D(64, 3, 3, activation='relu'))
model.add(Convolution2D(64, 3, 3, activation='relu'))
model.add(Flatten())
model.add(Dense(100))
model.add(Dense( 50))
model.add(Dense( 10))
model.add(Dense(  1))

print("Train...")

# Define early stopping callback to mitigate network overtraining.
# The early stopping criteria validation loss changes by less then 0.001
early_stop = EarlyStopping(monitor='val_loss', min_delta=0.001)

# Use Adam optimization with default parameters
# lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0
adam_opt = Adam()

# Use mean square error loss function.
model.compile(loss='mse', optimizer=adam_opt)

# Train the model using fit_generator. Generators are required because the 
# image data set size is too large to hold in memeory.  Thus, the generators
# read and process the images and measurments as batches.
# Set the number of epochs a large value (20) then using early_stop callback
# to terminate training.
history_object = model.fit_generator(fit_generator,
                                     samples_per_epoch = train_steps,
                                     validation_data = val_generator,
                                     nb_val_samples = valid_steps,
                                     nb_epoch = 20, verbose = 1,
                                     callbacks = [early_stop])

# save model data
model.save('model.h5')

# save traing history data
import pickle
with open('history.dat','wb') as f:
    pickle.dump(history_object.history, f)
f.close()